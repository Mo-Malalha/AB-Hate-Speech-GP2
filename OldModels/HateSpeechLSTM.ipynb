{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aefcjXug0Vx",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "ea2961cf-2bd5-4280-9d6c-f175100e80b6"
   },
   "outputs": [],
   "source": [
    "# !pip install vaderSentiment\n",
    "# !pip install textstat\n",
    "# !pip install pickle\n",
    "# !pip install joblib\n",
    "# !pip install keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer as VS\n",
    "from textstat.textstat import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vx0-JSQTg0V3"
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YnbGy2WHg0V4"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"E:\\lenovo\\Documents\\Jupyterstuff\\gp2\\labeled_data.csv\") Put own path or use colab under\n",
    "df = pd.read_csv(\"labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "8JZAdiaUg0V4",
    "outputId": "55859d45-d6e6-4b0e-d5ca-0eb1546e93f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>25291</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>25292</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>25294</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>25295</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>25296</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0               0      3            0                   0        3      2   \n",
       "1               1      3            0                   3        0      1   \n",
       "2               2      3            0                   3        0      1   \n",
       "3               3      3            0                   2        1      1   \n",
       "4               4      6            0                   6        0      1   \n",
       "...           ...    ...          ...                 ...      ...    ...   \n",
       "24778       25291      3            0                   2        1      1   \n",
       "24779       25292      3            0                   1        2      2   \n",
       "24780       25294      3            0                   3        0      1   \n",
       "24781       25295      6            0                   6        0      1   \n",
       "24782       25296      3            0                   0        3      2   \n",
       "\n",
       "                                                   tweet  \n",
       "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
       "...                                                  ...  \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
       "24779  you've gone and broke the wrong heart baby, an...  \n",
       "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
       "24781              youu got wild bitches tellin you lies  \n",
       "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
       "\n",
       "[24783 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "rH8R67Hdg0V6",
    "outputId": "11934647-a631-483e-e993-67bca40cf8be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "      <td>24783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12681.192027</td>\n",
       "      <td>3.243473</td>\n",
       "      <td>0.280515</td>\n",
       "      <td>2.413711</td>\n",
       "      <td>0.549247</td>\n",
       "      <td>1.110277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7299.553863</td>\n",
       "      <td>0.883060</td>\n",
       "      <td>0.631851</td>\n",
       "      <td>1.399459</td>\n",
       "      <td>1.113299</td>\n",
       "      <td>0.462089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6372.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12703.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18995.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25296.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         count   hate_speech  offensive_language  \\\n",
       "count  24783.000000  24783.000000  24783.000000        24783.000000   \n",
       "mean   12681.192027      3.243473      0.280515            2.413711   \n",
       "std     7299.553863      0.883060      0.631851            1.399459   \n",
       "min        0.000000      3.000000      0.000000            0.000000   \n",
       "25%     6372.500000      3.000000      0.000000            2.000000   \n",
       "50%    12703.000000      3.000000      0.000000            3.000000   \n",
       "75%    18995.500000      3.000000      0.000000            3.000000   \n",
       "max    25296.000000      9.000000      7.000000            9.000000   \n",
       "\n",
       "            neither         class  \n",
       "count  24783.000000  24783.000000  \n",
       "mean       0.549247      1.110277  \n",
       "std        1.113299      0.462089  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      1.000000  \n",
       "50%        0.000000      1.000000  \n",
       "75%        0.000000      1.000000  \n",
       "max        9.000000      2.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clNjQLbug0V7",
    "outputId": "590b155e-2a58-4194-d542-a8fb1ec4464d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n",
       "       'class', 'tweet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bmg4LFE7g0V7"
   },
   "source": [
    "### Columns key:\n",
    "count = number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were determined to be unreliable by CF).\n",
    "\n",
    "\n",
    "hate_speech = number of CF users who judged the tweet to be hate speech.\n",
    "\n",
    "\n",
    "offensive_language = number of CF users who judged the tweet to be offensive.\n",
    "\n",
    "\n",
    "neither = number of CF users who judged the tweet to be neither offensive nor non-offensive.\n",
    "\n",
    "\n",
    "class = class label for majority of CF users.\n",
    "\n",
    "    0 - hate speech\n",
    "    1 - offensive  language\n",
    "    2 - neither\n",
    "\n",
    "tweet = raw tweet text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "NhJ8DX0Vg0V8",
    "outputId": "46cf3e5c-cfc2-4c71-d0f4-9351333af56b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['class'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMbRITcPg0V8"
   },
   "source": [
    "This histogram shows the imbalanced nature of the task - most tweets containing \"hate\" words as defined by Hatebase were\n",
    "only considered to be offensive by the CF coders. More tweets were considered to be neither hate speech nor offensive language than were considered hate speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ca2M7ZIrg0V9"
   },
   "outputs": [],
   "source": [
    "tweets=df.tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section consisted of the basic stuff, reading the file, using describe on the data to find out the \"statistics\" of each column\n",
    "# Then we declared the 3 classes we will work on, 0 for hate, 1 for offensive, 2 for neither.\n",
    "# This histogram shows the imbalanced nature of the task,\n",
    "# most tweets containing \"hate\" words as defined by Hatebase were only considered to be offensive by the CF coders. \n",
    "# More tweets were considered to be neither hate speech nor offensive language than were considered hate speech.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GlL1lz6g0V-"
   },
   "source": [
    "## Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CoeBKNZkg0V-",
    "outputId": "931591be-1f12-4b55-e84b-090292a84778"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\win 10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\win\n",
      "[nltk_data]     10\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nGUnBqm0g0V_"
   },
   "outputs": [],
   "source": [
    "stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "other_exclusions = [\"#ff\", \"ff\", \"rt\"]\n",
    "stopwords.extend(other_exclusions)\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "# \"\"\" Stemming is a text normalization technique that cuts off the end or beginning of a word by taking into account\n",
    "# a list of common prefixes or suffixes that could be found in that word \"\"\" \"returns words to their root\"\n",
    "\n",
    "\n",
    "def preprocess(text_string):\n",
    "    # \"\"\"\n",
    "    # Accepts a text string and replaces:\n",
    "    # 1) urls with URLHERE\n",
    "    # 2) lots of whitespace with one instance\n",
    "    # 3) mentions with MENTIONHERE\n",
    "\n",
    "    # This allows us to get standardized counts of urls and mentions\n",
    "    # Without caring about specific people mentioned\n",
    "    # \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, '', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, '', parsed_text)\n",
    "    return parsed_text\n",
    "\n",
    "def tokenize(tweet):\n",
    "    # \"\"\"Removes punctuation & excess whitespace, sets to lowercase,\n",
    "    # and stems tweets. Returns a list of stemmed tokens.\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z]*\", tweet.lower())).strip()\n",
    "    tokens = [stemmer.stem(t) for t in tweet.split()]\n",
    "    return tokens\n",
    "\n",
    "def basic_tokenize(tweet):\n",
    "    # \"\"\"Same as tokenize but without the stemming\"\"\"\n",
    "    tweet = \" \".join(re.split(\"[^a-zA-Z.,!?]*\", tweet.lower())).strip()\n",
    "    return tweet.split()\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=tokenize,\n",
    "    preprocessor=preprocess,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=stopwords,\n",
    "    use_idf=True,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.75\n",
    "    )\n",
    "\n",
    "#TFIDF VECTORIZER \n",
    "# It can be defined as the calculation of how relevant a word in a series or corpus is to a text. \n",
    "# The meaning increases proportionally to the number of times in the text a word appears \n",
    "# but is compensated by the word frequency in the corpus (data-set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6dJZoj_hg0WA"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "#This just ignores future warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vnIF5oQGg0WB",
    "outputId": "2520cd54-89db-42c6-92e5-182fcb9ed922"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win 10\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\win 10\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\feature_extraction\\text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['b', 'c', 'e', 'f', 'g', 'h', 'j', 'l', 'n', 'p', 'r', 'u', 'v', 'w'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Construct tfidf matrix and get relevant scores\n",
    "tfidf = vectorizer.fit_transform(tweets).toarray()\n",
    "vocab = {v:i for i, v in enumerate(vectorizer.get_feature_names_out())}\n",
    "idf_vals = vectorizer.idf_\n",
    "idf_dict = {i:idf_vals[i] for i in vocab.values()} #keys are indices; values are IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.29163073 0.         0.         ... 0.         0.         0.        ]\n",
      " [2.58326146 0.         0.         ... 0.         0.         0.        ]\n",
      " [2.58326146 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [1.29163073 0.         0.         ... 0.         0.         0.        ]\n",
      " [1.29163073 0.         0.         ... 0.         0.         0.        ]\n",
      " [2.58326146 0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Breaking down last cell\n",
    "# print(vectorizer.fit_transform(tweets))\n",
    "# transforms the tweets into a sparse matrix representation \n",
    "# where each row represents a tweet and each column represents a unique word in the entire collection of tweets.\n",
    "\n",
    "print(vectorizer.fit_transform(tweets).toarray())\n",
    "# This converts the sparse matrix representation into a dense NumPy array.  \n",
    "# The resulting tfidf array contains the TF-IDF values for each word in each tweet.\n",
    "\n",
    "# Vocab is a dictionary where keys are unique words in the entire collection of tweets (retrieved using vectorizer.get_feature_names_out()) \n",
    "# and values are their corresponding indices in the TF-IDF matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fx7rW3xng0WB"
   },
   "outputs": [],
   "source": [
    "#Get POS tags for tweets and save as a string\n",
    "\n",
    "tweet_tags = []\n",
    "for t in tweets:\n",
    "    tokens = basic_tokenize(preprocess(t))\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    tag_list = [x[1] for x in tags]\n",
    "    tag_str = \" \".join(tag_list)\n",
    "    tweet_tags.append(tag_str)\n",
    "\n",
    "# The for loop processes a collection of tweets, tokenizes and preprocesses each tweet, \n",
    "# assigns part-of-speech tags to the tokens, and then stores the sequences of part-of-speech tags for each tweet in a list called tweet_tags.\n",
    "#POS tagging, it uses grammer stuff like nouns and verbs adjactives for each word because it helps in understanding the syntax structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fvAMHhs5g0WB"
   },
   "outputs": [],
   "source": [
    "#We can use the TFIDF vectorizer to get a token matrix for the POS tags\n",
    "pos_vectorizer = TfidfVectorizer(\n",
    "    tokenizer=None,\n",
    "    lowercase=False,\n",
    "    preprocessor=None,\n",
    "    ngram_range=(1, 3),\n",
    "    stop_words=None,\n",
    "    use_idf=False,\n",
    "    smooth_idf=False,\n",
    "    norm=None,\n",
    "    decode_error='replace',\n",
    "    max_features=5000,\n",
    "    min_df=5,\n",
    "    max_df=0.75,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4Aus2m2Ng0WC"
   },
   "outputs": [],
   "source": [
    "#Construct POS TF matrix and get vocab dict\n",
    "pos = pos_vectorizer.fit_transform(pd.Series(tweet_tags)).toarray()\n",
    "pos_vocab = {v:i for i, v in enumerate(pos_vectorizer.get_feature_names_out())}\n",
    "\n",
    "#Last two cells are the same as the previous tfidf method, were making a tokens matrix for POS tags this time\n",
    "#then making a tfidf matrix and then getting the vocab dictionary, all for pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "RSj08xWsg0WC"
   },
   "outputs": [],
   "source": [
    "#Now get other features\n",
    "sentiment_analyzer = VS()\n",
    "\n",
    "def count_twitter_objs(text_string):\n",
    "    # \"\"\" function just for statistics\n",
    "    # Accepts a text string and replaces:\n",
    "    # 1) urls with URLHERE\n",
    "    # 2) lots of whitespace with one instance\n",
    "    # 3) mentions with MENTIONHERE\n",
    "    # 4) hashtags with HASHTAGHERE\n",
    "\n",
    "    # This allows us to get standardized counts of urls and mentions\n",
    "    # Without caring about specific people mentioned.\n",
    "\n",
    "    # Returns counts of urls, mentions, and hashtags.\n",
    "    # \"\"\"\n",
    "    space_pattern = '\\s+'\n",
    "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
    "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    mention_regex = '@[\\w\\-]+'\n",
    "    hashtag_regex = '#[\\w\\-]+'\n",
    "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
    "    parsed_text = re.sub(giant_url_regex, 'URLHERE', parsed_text)\n",
    "    parsed_text = re.sub(mention_regex, 'MENTIONHERE', parsed_text)\n",
    "    parsed_text = re.sub(hashtag_regex, 'HASHTAGHERE', parsed_text)\n",
    "    return(parsed_text.count('URLHERE'),parsed_text.count('MENTIONHERE'),parsed_text.count('HASHTAGHERE'))\n",
    "\n",
    "def other_features(tweet):\n",
    "    # \"\"\"This function takes a string and returns a list of features.\n",
    "    # These include Sentiment scores, Text and Readability scores,\n",
    "    # as well as Twitter specific features\"\"\"\n",
    "    sentiment = sentiment_analyzer.polarity_scores(tweet)\n",
    "\n",
    "    words = preprocess(tweet) #Get text only\n",
    "\n",
    "    syllables = textstat.syllable_count(words)\n",
    "    num_chars = sum(len(w) for w in words)\n",
    "    num_chars_total = len(tweet)\n",
    "    num_terms = len(tweet.split())\n",
    "    num_words = len(words.split())\n",
    "    avg_syl = round(float((syllables+0.001))/float(num_words+0.001),4)\n",
    "    num_unique_terms = len(set(words.split()))\n",
    "\n",
    "    ###Modified FK grade, where avg words per sentence is just num words/1\n",
    "    FKRA = round(float(0.39 * float(num_words)/1.0) + float(11.8 * avg_syl) - 15.59,1)\n",
    "    ##Modified FRE score, where sentence fixed to 1\n",
    "    FRE = round(206.835 - 1.015*(float(num_words)/1.0) - (84.6*float(avg_syl)),2)\n",
    "\n",
    "    twitter_objs = count_twitter_objs(tweet)\n",
    "    retweet = 0\n",
    "    if \"rt\" in words:\n",
    "        retweet = 1\n",
    "    features = [FKRA, FRE,syllables, avg_syl, num_chars, num_chars_total, num_terms, num_words,\n",
    "                num_unique_terms, sentiment['neg'], sentiment['pos'], sentiment['neu'], sentiment['compound'],\n",
    "                twitter_objs[2], twitter_objs[1],\n",
    "                twitter_objs[0], retweet]\n",
    "    #features = pandas.DataFrame(features)\n",
    "    return features\n",
    "\n",
    "def get_feature_array(tweets):\n",
    "    feats=[]\n",
    "    for t in tweets:\n",
    "        feats.append(other_features(t))\n",
    "    return np.array(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It calculates sentiment scores using a sentiment analyzer. (negative, positive, neutral)\n",
    "# Then,it preprocesses the tweet to extract text-only content and computes various metrics such as syllable count, \n",
    "# character count, word count, average syllables per word, and number of unique terms. \n",
    "\n",
    "# Then it calculates modified versions of Flesch-Kincaid Readability (FKRA) and Flesch Reading Ease (FRE) scores tailored for tweets. \"How easy the data is to read\"\n",
    "# It also identifies Twitter-specific features like mentions, hashtags, and URLs. \n",
    "\n",
    "# Then it constructs a list containing all these features and returns it. \n",
    "# This function is useful for extracting meaningful information from tweets for tasks such as sentiment analysis, \n",
    "# readability assessment, and Twitter-specific analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "npgdeKCFg0WD"
   },
   "outputs": [],
   "source": [
    "other_features_names = [\"FKRA\", \"FRE\",\"num_syllables\", \"avg_syl_per_word\", \"num_chars\", \"num_chars_total\", \\\n",
    "                        \"num_terms\", \"num_words\", \"num_unique_words\", \"vader neg\",\"vader pos\",\"vader neu\", \\\n",
    "                        \"vader compound\", \"num_hashtags\", \"num_mentions\", \"num_urls\", \"is_retweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "av-Fopadg0WE"
   },
   "outputs": [],
   "source": [
    "feats = get_feature_array(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "uL_IIMCkg0WE"
   },
   "outputs": [],
   "source": [
    "#Now join them all up\n",
    "M = np.concatenate([tfidf,pos,feats],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4SngMDfg0WE",
    "outputId": "9418f05f-e28a-4180-ed64-b8e06ed5df88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 4023)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "SmSZelbJg0WE"
   },
   "outputs": [],
   "source": [
    "#Finally get a list of variable names\n",
    "variables = ['']*len(vocab)\n",
    "for k,v in vocab.items():\n",
    "    variables[v] = k\n",
    "\n",
    "pos_variables = ['']*len(pos_vocab)\n",
    "for k,v in pos_vocab.items():\n",
    "    pos_variables[v] = k\n",
    "\n",
    "feature_names = variables+pos_variables+other_features_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbGlz_Mvg0WF"
   },
   "source": [
    "# Running the model\n",
    "\n",
    "The best model was selected using a GridSearch with 5-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "y1UqcI5Mg0WG"
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame(M)\n",
    "y = df['class'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "QP2PCaa2g0WG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "eNRRaAM9g0WH"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uBlkZX0Zg0WH"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "SYVFnD6tg0WH"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\__internal__\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\__internal__\\backend\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\__init__.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\applications\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtSmall\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\applications\\convnext.py:26\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"ConvNeXt models for Keras.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03mReferences:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m  (CVPR 2022)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initializers\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\__init__.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "\n",
    "# Define the LSTM model\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=input_shape))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the pipeline with LSTM model\n",
    "pipe = Pipeline([\n",
    "    ('select', SelectFromModel(LogisticRegression(class_weight='balanced', penalty=\"l2\", C=0.01, max_iter=1500))),\n",
    "    ('model', create_lstm_model(input_shape=(X_train.shape[1], 1)))  # Adjust input shape accordingly\n",
    "])\n",
    "\n",
    "# Fit the pipeline to your training data\n",
    "model = pipe.fit(np.expand_dims(X_train, axis=-1), y_train)  # Adjust input shape accordingly\n",
    "\n",
    "# Get the best parameters and score (not applicable for LSTM)\n",
    "best_params = None\n",
    "best_score = model.score(np.expand_dims(X_train, axis=-1), y_train)  # Adjust input shape accordingly\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUr3kHukg0WK"
   },
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhDT7Js-g0WK"
   },
   "source": [
    "## Evaluating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fi5nzsTdg0WK"
   },
   "outputs": [],
   "source": [
    "report = classification_report( y_test, y_preds )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWIHTArHg0WL"
   },
   "source": [
    "***Note: Results in paper are from best model retrained on the entire dataset (see the other notebook). Here the results are reported after using cross-validation and only for the held-out set.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kv50vqF7g0WL",
    "outputId": "777ed43b-ce47-41f2-c46e-0c9a09a534c8"
   },
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "o3VKZtgqg0WN",
    "outputId": "50f45717-3770-4e93-f4cd-6068e43565b2"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test,y_preds)\n",
    "matrix_proportions = np.zeros((3,3))\n",
    "for i in range(0,3):\n",
    "    matrix_proportions[i,:] = confusion_matrix[i,:]/float(confusion_matrix[i,:].sum())\n",
    "names=['Hate','Offensive','Neither']\n",
    "confusion_df = pd.DataFrame(matrix_proportions, index=names,columns=names)\n",
    "plt.figure(figsize=(5,5))\n",
    "seaborn.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
    "plt.ylabel(r'True categories',fontsize=14)\n",
    "plt.xlabel(r'Predicted categories',fontsize=14)\n",
    "plt.tick_params(labelsize=12)\n",
    "\n",
    "# Basic Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "KXHxUt8xg0WO",
    "outputId": "9c2dcae9-b6d5-4732-9d56-1a9fbc74f7ea"
   },
   "outputs": [],
   "source": [
    "#True distribution\n",
    "y.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "wbMWryZeg0WO",
    "outputId": "1ebefc3a-43d9-42ad-9e70-a3b01b2893f0"
   },
   "outputs": [],
   "source": [
    "pd.Series(y_preds).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIV-y00Qg0WP"
   },
   "outputs": [],
   "source": [
    "#Saving the Model\n",
    "# joblib.dump(model.best_estimator_, 'HateSpeechTestrun_Model.pkl')\n",
    "# joblib.load(\"HateSpeechTestrun_Model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
